{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:36:45.350260Z",
     "start_time": "2025-08-05T19:36:45.344058Z"
    }
   },
   "cell_type": "code",
   "source": "import regex as re",
   "id": "23f09f82febd8f11",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-03T19:40:14.561317Z",
     "start_time": "2025-08-03T19:40:14.558218Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4,
   "source": "chr(0)",
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:39:49.513080Z",
     "start_time": "2025-08-03T19:39:49.510017Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2,
   "source": "ord('\\x00')",
   "id": "6270be52656a6cca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:40:19.490383Z",
     "start_time": "2025-08-03T19:40:19.487623Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 5,
   "source": "print(0)",
   "id": "effa91428c12e7f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:40:25.514449Z",
     "start_time": "2025-08-03T19:40:25.511569Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "execution_count": 6,
   "source": "print(chr(0))",
   "id": "d1b0d2ce34b90100"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:41:16.861834Z",
     "start_time": "2025-08-03T19:41:16.859076Z"
    }
   },
   "cell_type": "code",
   "source": "'test' + chr(0) + 'test'",
   "id": "d842b3aaa5819391",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test\\x00test'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:41:23.277104Z",
     "start_time": "2025-08-03T19:41:23.274869Z"
    }
   },
   "cell_type": "code",
   "source": "print('test' + chr(0) + 'test')",
   "id": "6ca808ed9abead26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\u0000test\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:42:52.805705Z",
     "start_time": "2025-08-03T19:42:52.803915Z"
    }
   },
   "cell_type": "code",
   "source": "test_string = \"hello! こんにちは!\"",
   "id": "27731b5d2a3f5c5a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:43:08.357393Z",
     "start_time": "2025-08-03T19:43:08.355618Z"
    }
   },
   "cell_type": "code",
   "source": "utf8_encoded = test_string.encode('utf-8')",
   "id": "11410bda7a4049",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:43:14.149526Z",
     "start_time": "2025-08-03T19:43:14.147196Z"
    }
   },
   "cell_type": "code",
   "source": "print(utf8_encoded)",
   "id": "48361c67dbc3c440",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello! \\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf!'\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:43:31.023091Z",
     "start_time": "2025-08-03T19:43:31.021230Z"
    }
   },
   "cell_type": "code",
   "source": "print(type(utf8_encoded))",
   "id": "bd51b9a11fe758d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:43:51.438511Z",
     "start_time": "2025-08-03T19:43:51.436985Z"
    }
   },
   "cell_type": "code",
   "source": "print(list(utf8_encoded))",
   "id": "ebec6ac07608209b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 101, 108, 108, 111, 33, 32, 227, 129, 147, 227, 130, 147, 227, 129, 171, 227, 129, 161, 227, 129, 175, 33]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:44:26.431883Z",
     "start_time": "2025-08-03T19:44:26.430053Z"
    }
   },
   "cell_type": "code",
   "source": "print(utf8_encoded.decode('utf-8'))",
   "id": "8315b601da20bd22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello! こんにちは!\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:47:23.175862Z",
     "start_time": "2025-08-03T19:47:23.174048Z"
    }
   },
   "cell_type": "code",
   "source": "test_string.encode()[0]",
   "id": "fa06456d976cb7a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:46:54.095299Z",
     "start_time": "2025-08-03T19:46:54.092130Z"
    }
   },
   "cell_type": "code",
   "source": "chr(test_string.encode()[0])",
   "id": "cb1e784c15db1dec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:49:20.529547Z",
     "start_time": "2025-08-03T19:49:20.527345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])"
   ],
   "id": "3f66d8af36eeb719",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:49:28.579046Z",
     "start_time": "2025-08-03T19:49:28.576538Z"
    }
   },
   "cell_type": "code",
   "source": "decode_utf8_bytes_to_str_wrong(\"hello\".encode(\"utf-8\"))",
   "id": "4f949c7634d68fe2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:49:36.575320Z",
     "start_time": "2025-08-03T19:49:36.572208Z"
    }
   },
   "cell_type": "code",
   "source": "decode_utf8_bytes_to_str_wrong(\"hello0123hello\".encode(\"utf-8\"))",
   "id": "fde5d8df706e06b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello0123hello'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:57:20.582665Z",
     "start_time": "2025-08-03T19:57:20.580578Z"
    }
   },
   "cell_type": "code",
   "source": "test_multiple_bytes_per_char = \"こんにちは!\".encode(\"utf-8\")",
   "id": "7c7fbed493cd9d72",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T20:03:47.652993Z",
     "start_time": "2025-08-03T20:03:47.651203Z"
    }
   },
   "cell_type": "code",
   "source": "list(test_multiple_bytes_per_char)",
   "id": "672ec473d4195315",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[227, 129, 147, 227, 130, 147, 227, 129, 171, 227, 129, 161, 227, 129, 175, 33]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:57:44.333631Z",
     "start_time": "2025-08-03T19:57:44.330555Z"
    }
   },
   "cell_type": "code",
   "source": "len(test_multiple_bytes_per_char)",
   "id": "9b133f6934ee85db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:57:55.091284Z",
     "start_time": "2025-08-03T19:57:55.087665Z"
    }
   },
   "cell_type": "code",
   "source": "len(\"こんにちは!\")",
   "id": "7f457ad4976d79c1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:57:32.463865Z",
     "start_time": "2025-08-03T19:57:32.460722Z"
    }
   },
   "cell_type": "code",
   "source": "test_multiple_bytes_per_char.decode(\"utf-8\")",
   "id": "b54db0b275f9a4ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'こんにちは!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T19:51:49.145902Z",
     "start_time": "2025-08-03T19:51:49.126837Z"
    }
   },
   "cell_type": "code",
   "source": "decode_utf8_bytes_to_str_wrong(\"こんにちは!\".encode(\"utf-8\"))",
   "id": "44ef319c5cb2382f",
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe3 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mUnicodeDecodeError\u001B[39m                        Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mdecode_utf8_bytes_to_str_wrong\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mこんにちは!\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 2\u001B[39m, in \u001B[36mdecode_utf8_bytes_to_str_wrong\u001B[39m\u001B[34m(bytestring)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecode_utf8_bytes_to_str_wrong\u001B[39m(bytestring: \u001B[38;5;28mbytes\u001B[39m):\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m.join([\u001B[38;5;28;43mbytes\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mb\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m bytestring])\n",
      "\u001B[31mUnicodeDecodeError\u001B[39m: 'utf-8' codec can't decode byte 0xe3 in position 0: unexpected end of data"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:37:08.626505Z",
     "start_time": "2025-08-05T19:37:08.625108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# regex to pre-tokenize text\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\""
   ],
   "id": "a3f98288648e37f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:37:09.229285Z",
     "start_time": "2025-08-05T19:37:09.224155Z"
    }
   },
   "cell_type": "code",
   "source": "re.findall(PAT, \"hello! こんにちは! 1234 test's\")",
   "id": "e0013373e42a6093",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', '!', ' こんにちは', '!', ' 1234', ' test', \"'s\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T20:41:35.971571Z",
     "start_time": "2025-08-06T20:41:35.968163Z"
    }
   },
   "cell_type": "code",
   "source": "re.findall(PAT, \"<|endoftext|>\")",
   "id": "cfa7b29a51d4e86a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|', 'endoftext', '|>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:43:40.391749Z",
     "start_time": "2025-08-05T19:43:40.389681Z"
    }
   },
   "cell_type": "code",
   "source": "test = re.finditer(PAT, \"hello! こんにちは! 1234 test's\")",
   "id": "6c0b01ffe655f0e6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T19:43:40.753662Z",
     "start_time": "2025-08-05T19:43:40.751086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for t in test:\n",
    "    # print(t)\n",
    "    print(t.group())"
   ],
   "id": "b6dfc0d01e7f5108",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "!\n",
      " こんにちは\n",
      "!\n",
      " 1234\n",
      " test\n",
      "'s\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ee16e2d6630c2bfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T20:05:10.090021Z",
     "start_time": "2025-08-03T20:05:10.087711Z"
    }
   },
   "cell_type": "code",
   "source": "max([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"ZZ\"), (\"BA\", \"A\")])",
   "id": "d66e5948cf9cbca3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BA', 'A')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:39:51.886714Z",
     "start_time": "2025-08-06T14:39:51.883689Z"
    }
   },
   "cell_type": "code",
   "source": "b\"<|endoftext|>\"",
   "id": "6124bb24216b1df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<|endoftext|>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T14:40:09.067015Z",
     "start_time": "2025-08-06T14:40:09.065041Z"
    }
   },
   "cell_type": "code",
   "source": "'<|endoftext|>'.encode()",
   "id": "d0292275a2b5d174",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<|endoftext|>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T15:19:09.594665Z",
     "start_time": "2025-08-06T15:19:09.592320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = [0, 21617, 44228, 65990, 112162, 133404, 154501, 173416, 195049, 214745, 235474, 259537, 284470, 303341, 323275, 348727, 365262, 391375, 407618, 448003, 449080, 471094, 492754, 516179, 534993, 557151, 578551, 634115, 641463, 667851, 683599]\n",
    "b = [0, 21617, 44228, 65990, 112162, 133404, 154501, 173416, 195049, 214745, 235474, 259537, 284470, 303341, 323275, 348727, 365262, 391375, 407618, 448003, 449080, 471094, 492754, 516179, 534993, 557151, 578551, 634115, 641463, 667851, 683599]"
   ],
   "id": "435c5b2a64109797",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T15:19:12.586754Z",
     "start_time": "2025-08-06T15:19:12.584198Z"
    }
   },
   "cell_type": "code",
   "source": "a ==b",
   "id": "504238564ff71572",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a93644ad5af4559"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T16:50:58.302654Z",
     "start_time": "2025-08-07T16:50:58.299410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = [0, 21617, 44228, 65990, 112162, 133404, 154501, 173416, 195049, 214745, 235474, 259537, 284470, 303341, 323275, 348727, 365262, 391375, 407618, 448003]\n",
    "n = 4\n",
    "\n",
    "l = int(len(a) / n)+ 1\n",
    "print(len(a))\n",
    "print(l)\n",
    "print(len(a) / n)\n",
    "\n",
    "\n",
    "t = [a[i:i + l] for i in range(0, len(a), l)]\n",
    "\n",
    "print(t)\n",
    "\n"
   ],
   "id": "b060ba57242507fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "6\n",
      "5.0\n",
      "[[0, 21617, 44228, 65990, 112162, 133404], [154501, 173416, 195049, 214745, 235474, 259537], [284470, 303341, 323275, 348727, 365262, 391375], [407618, 448003]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "465606e8233c0494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "27ea08d02b37421b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a14055ce3205cc46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T17:41:29.125044Z",
     "start_time": "2025-08-08T17:41:29.101751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = (0, 1, 2, 3, 4, 5, 3, 4, 7, 3, 4, 9, 3, 1, 4, 2, 5, 4, 3, 4, 3)\n",
    "b = (3, 4)\n",
    "\n",
    "byte_1 = b[0]\n",
    "byte_2 = b[1]\n",
    "new_token_id = -99\n",
    "temp_word = [] # this contains a sequence of bytes\n",
    "print(a)\n",
    "print(b)\n",
    "merges = 0\n",
    "end_of_word = False\n",
    "try:\n",
    "    while True:\n",
    "        byte_1_index = a.index(byte_1, len(temp_word)+merges)\n",
    "        print('byte_1_index:', byte_1_index)\n",
    "        c += 1\n",
    "        if a[byte_1_index + 1] == byte_2:\n",
    "            print('byte_1_index + 1 is byte_2', byte_2)\n",
    "            print('copy a[len(temp_word)+merges:byte_1_index] to temp_word')\n",
    "            print(a[len(temp_word)+merges:byte_1_index])\n",
    "\n",
    "            temp_word += list(a[len(temp_word)+merges:byte_1_index]) # copy all bytes before byte_1\n",
    "            print(f'temp_word: {temp_word}')\n",
    "            temp_word.append(new_token_id) # append new token id - a token for merged bytes\n",
    "            print('append new token id')\n",
    "            print(f'temp_word: {temp_word}')\n",
    "            merges += 1\n",
    "            print('='*20)\n",
    "            # I need to merge them and update counts. think what counts to update\n",
    "            # be careful because potentialy a best pair can be 10, 20 and the word can be (30, 10, 20, 10, 20, 30)\n",
    "            # so we need to replace all. because of it we shouldn't break and just wait until it ValueError\n",
    "        else:\n",
    "            print('byte_1_index + 1 is NOT byte_2', byte_2)\n",
    "            temp_word += list(a[len(temp_word)+merges:byte_1_index+1]) # copy all bytes before and byte_1\n",
    "\n",
    "        print(f'current temp_word: {temp_word}, len(temp_word): {len(temp_word)}, merges: {merges}')\n",
    "        print(f'len(a): {len(a)}, len(temp_word) + merges: {len(temp_word) + merges}')\n",
    "        if len(temp_word) + merges == len(a):\n",
    "            print('end of word')\n",
    "            end_of_word = True\n",
    "        else:\n",
    "            print('end of word is not reached')\n",
    "            end_of_word = False\n",
    "except ValueError:\n",
    "    print('ValueError - no more find')\n",
    "\n",
    "if end_of_word == False:\n",
    "    temp_word += list(a[len(temp_word)+merges:]) # copy all bytes after byte_1\n",
    "    print(f'temp_word: {temp_word}')\n",
    "\n"
   ],
   "id": "dfb4236316e7f72f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3, 4, 5, 3, 4, 7, 3, 4, 9, 3, 1, 4, 2, 5, 4, 3, 4, 3)\n",
      "(3, 4)\n",
      "byte_1_index: 3\n",
      "byte_1_index + 1 is byte_2 4\n",
      "copy a[len(temp_word)+merges:byte_1_index] to temp_word\n",
      "(0, 1, 2)\n",
      "temp_word: [0, 1, 2]\n",
      "append new token id\n",
      "temp_word: [0, 1, 2, -99]\n",
      "====================\n",
      "current temp_word: [0, 1, 2, -99], len(temp_word): 4, merges: 1\n",
      "len(a): 21, len(temp_word) + merges: 5\n",
      "end of word is not reached\n",
      "byte_1_index: 6\n",
      "byte_1_index + 1 is byte_2 4\n",
      "copy a[len(temp_word)+merges:byte_1_index] to temp_word\n",
      "(5,)\n",
      "temp_word: [0, 1, 2, -99, 5]\n",
      "append new token id\n",
      "temp_word: [0, 1, 2, -99, 5, -99]\n",
      "====================\n",
      "current temp_word: [0, 1, 2, -99, 5, -99], len(temp_word): 6, merges: 2\n",
      "len(a): 21, len(temp_word) + merges: 8\n",
      "end of word is not reached\n",
      "byte_1_index: 9\n",
      "byte_1_index + 1 is byte_2 4\n",
      "copy a[len(temp_word)+merges:byte_1_index] to temp_word\n",
      "(7,)\n",
      "temp_word: [0, 1, 2, -99, 5, -99, 7]\n",
      "append new token id\n",
      "temp_word: [0, 1, 2, -99, 5, -99, 7, -99]\n",
      "====================\n",
      "current temp_word: [0, 1, 2, -99, 5, -99, 7, -99], len(temp_word): 8, merges: 3\n",
      "len(a): 21, len(temp_word) + merges: 11\n",
      "end of word is not reached\n",
      "byte_1_index: 12\n",
      "byte_1_index + 1 is NOT byte_2 4\n",
      "current temp_word: [0, 1, 2, -99, 5, -99, 7, -99, 9, 3], len(temp_word): 10, merges: 3\n",
      "len(a): 21, len(temp_word) + merges: 13\n",
      "end of word is not reached\n",
      "byte_1_index: 18\n",
      "byte_1_index + 1 is byte_2 4\n",
      "copy a[len(temp_word)+merges:byte_1_index] to temp_word\n",
      "(1, 4, 2, 5, 4)\n",
      "temp_word: [0, 1, 2, -99, 5, -99, 7, -99, 9, 3, 1, 4, 2, 5, 4]\n",
      "append new token id\n",
      "temp_word: [0, 1, 2, -99, 5, -99, 7, -99, 9, 3, 1, 4, 2, 5, 4, -99]\n",
      "====================\n",
      "current temp_word: [0, 1, 2, -99, 5, -99, 7, -99, 9, 3, 1, 4, 2, 5, 4, -99], len(temp_word): 16, merges: 4\n",
      "len(a): 21, len(temp_word) + merges: 20\n",
      "end of word is not reached\n",
      "byte_1_index: 20\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     15\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mbyte_1_index:\u001B[39m\u001B[33m'\u001B[39m, byte_1_index)\n\u001B[32m     16\u001B[39m c += \u001B[32m1\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43ma\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbyte_1_index\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m == byte_2:\n\u001B[32m     18\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mbyte_1_index + 1 is byte_2\u001B[39m\u001B[33m'\u001B[39m, byte_2)\n\u001B[32m     19\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mcopy a[len(temp_word)+merges:byte_1_index] to temp_word\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mIndexError\u001B[39m: tuple index out of range"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T18:04:44.048153Z",
     "start_time": "2025-08-08T18:04:44.043123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t = (1, 2, 3, 4)\n",
    "t[0]"
   ],
   "id": "be4b73a1d29310b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T18:21:12.070336Z",
     "start_time": "2025-08-08T18:21:06.575451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "best_pair = (3, 4)\n",
    "# print(len(word))\n",
    "# print(len(word)/21)\n",
    "\n",
    "byte_1, byte_2 = best_pair\n",
    "new_token_id = -99\n",
    "new_word = []\n",
    "current_pos = 1 # starting from the second element because we will search for byte_2 and check word[byte_2_index - 1]\n",
    "# if the first element is actually byte_1, we may need to merge it, so don't append it yet\n",
    "if word[0] != byte_1:\n",
    "    new_word.append(word[0])\n",
    "# print(new_word)\n",
    "while current_pos < len(word):\n",
    "    try:\n",
    "        # Find the next occurrence of byte_2 starting from our current position\n",
    "        next_b2_index = word.index(byte_2, current_pos)\n",
    "\n",
    "        # Check if it's the pair we want to merge\n",
    "        if word[next_b2_index - 1] == byte_1:\n",
    "            # It's a match! Copy everything before the index of byte_1 which is next_b2_index - 1\n",
    "            new_word += list(word[current_pos:next_b2_index - 1])\n",
    "            # Append the new merged token.\n",
    "            new_word.append(new_token_id)\n",
    "            # Update our position to be after the merged pair.\n",
    "            current_pos = next_b2_index + 1\n",
    "        else:\n",
    "            # It's not a match. Copy up to and including this byte_2.\n",
    "            new_word += list(word[current_pos : next_b2_index + 1])\n",
    "            # Update our position to start searching right after it.\n",
    "            current_pos = next_b2_index + 1\n",
    "\n",
    "    except ValueError:\n",
    "        # .index() raised a ValueError, meaning no more byte_2s were found.\n",
    "        # Copy the rest of the word and we're done.\n",
    "        new_word += list(word[current_pos:])\n",
    "        break\n",
    "\n",
    "# print(word)\n",
    "# print(best_pair)\n",
    "# print(new_word)"
   ],
   "id": "33eef67956af7ce4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673 μs ± 7.04 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T18:16:06.342629Z",
     "start_time": "2025-08-08T18:16:06.341239Z"
    }
   },
   "cell_type": "code",
   "source": "a = word",
   "id": "4a2d69a3f59072b8",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T19:25:54.874073Z",
     "start_time": "2025-08-08T19:25:42.356992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "def merge_word_with_index(word: tuple, best_pair: tuple, new_token_id: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Efficiently merges pairs using the .index() method to find candidates.\n",
    "    This follows your proposed algorithm.\n",
    "    \"\"\"\n",
    "    byte_1, byte_2 = best_pair\n",
    "\n",
    "    new_word = []\n",
    "    current_pos = 0 # This is the start of the part of the word we still need to process\n",
    "    old_pairs = []\n",
    "    new_pairs = []\n",
    "    while current_pos < len(word):\n",
    "        try:\n",
    "            # Find the next occurrence of byte_1 starting from our current position\n",
    "            next_b1_index = word.index(byte_1, current_pos)\n",
    "\n",
    "            # Check for the IndexError edge case\n",
    "            if next_b1_index + 1 >= len(word):\n",
    "                # byte_1 is the last element, so it can't be part of a pair.\n",
    "                # Copy the rest of the word and we're done.\n",
    "                new_word.extend(word[current_pos:])\n",
    "                break\n",
    "\n",
    "            # Check if it's the pair we want to merge\n",
    "            if word[next_b1_index + 1] == byte_2:\n",
    "                # It's a match! Copy everything before it.\n",
    "                new_word.extend(word[current_pos:next_b1_index])\n",
    "                # Append the new merged token.\n",
    "                new_word.append(new_token_id)\n",
    "\n",
    "                #update the old and new pairs\n",
    "                old_pairs.append((word[next_b1_index - 1], byte_1)) # add the old pair with byte_1\n",
    "                old_pairs.append((byte_2, word[next_b1_index + 2])) # add the old pair with byte_2\n",
    "                new_pairs.append((word[next_b1_index - 1], new_token_id)) # add the new pair with prev token\n",
    "                new_pairs.append((new_token_id, word[next_b1_index + 2])) # add the new pair with the next token\n",
    "\n",
    "                # Update our position to be after the merged pair.\n",
    "                current_pos = next_b1_index + 2\n",
    "            else:\n",
    "                # It's not a match. Copy up to and including this byte_1.\n",
    "                new_word.extend(word[current_pos : next_b1_index + 1])\n",
    "                # Update our position to start searching right after it.\n",
    "                current_pos = next_b1_index + 1\n",
    "\n",
    "        except ValueError:\n",
    "            # .index() raised a ValueError, meaning no more byte_1s were found.\n",
    "            # Copy the rest of the word and we're done.\n",
    "            new_word.extend(word[current_pos:])\n",
    "            break\n",
    "\n",
    "    return tuple(new_word), set(old_pairs), set(new_pairs)\n",
    "\n",
    "# --- Example Usage ---\n",
    "a = (0, 1, 2, 3, 4, 2, 3, 4, 7, 3, 4, 9, 3, 1, 4, 2, 5, 4, 3, 4, 4)\n",
    "best_pair = (3, 4)\n",
    "new_token_id = -99\n",
    "\n",
    "final_word, old_pairs, new_pairs = merge_word_with_index(a, best_pair, new_token_id)\n",
    "# print(f\"Original word: {a}\")\n",
    "# print(f\"Final merged word: {final_word}\")\n",
    "# Correct Output: (0, 1, 2, -99, 5, -99, 7, -99, 9, 3, 1, 4, 2, 5, 4, -99, 3)"
   ],
   "id": "796a71699042ad16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54 μs ± 18.3 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T19:30:09.408362Z",
     "start_time": "2025-08-08T19:29:56.936419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "def _merge_word_with_index(word: tuple, best_pair: tuple, new_token_id: int) -> tuple:\n",
    "    byte_1, byte_2 = best_pair\n",
    "\n",
    "    new_word = []\n",
    "    old_pairs = []\n",
    "    new_pairs = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if i < len(word) - 1 and (word[i], word[i + 1]) == best_pair:\n",
    "            # Found the pair to merge!\n",
    "\n",
    "            # If there's a token before, the pair (prev, byte_1) becomes (prev, new_token_id)\n",
    "            if i > 0:\n",
    "                old_pairs.append((word[i - 1], byte_1))\n",
    "                new_pairs.append((word[i - 1], new_token_id))\n",
    "\n",
    "            # If there's a token after, the pair (byte_2, next) becomes (new_token_id, next)\n",
    "            if i + 2 < len(word):\n",
    "                old_pairs.append((byte_2, word[i + 2]))\n",
    "                new_pairs.append((new_token_id, word[i + 2]))\n",
    "\n",
    "            # Add the merged token\n",
    "            new_word.append(new_token_id)\n",
    "            i += 2  # Skip both bytes of the merged pair\n",
    "        else:\n",
    "            new_word.append(word[i])\n",
    "            i += 1\n",
    "\n",
    "    return tuple(new_word), set(old_pairs), set(new_pairs)\n",
    "# --- Example Usage ---\n",
    "a = (0, 1, 2, 3, 4, 2, 3, 4, 7, 3, 4, 9, 3, 1, 4, 2, 5, 4, 3, 4, 4)\n",
    "best_pair = (3, 4)\n",
    "new_token_id = -99\n",
    "\n",
    "final_word, old_pairs, new_pairs = merge_word_with_index(a, best_pair, new_token_id)"
   ],
   "id": "b7b90a5c1eac7f65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54 μs ± 12.4 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T19:17:48.631969Z",
     "start_time": "2025-08-08T19:17:48.630052Z"
    }
   },
   "cell_type": "code",
   "source": "old_pairs",
   "id": "5815cd52238699cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 3), (4, 2), (4, 3), (4, 4), (4, 7), (4, 9), (7, 3)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T19:17:51.195195Z",
     "start_time": "2025-08-08T19:17:51.192329Z"
    }
   },
   "cell_type": "code",
   "source": "new_pairs",
   "id": "786688756522a2de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-99, 2), (-99, 4), (-99, 7), (-99, 9), (2, -99), (4, -99), (7, -99)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    " At index 92 diff: (b' c', b'om') != (b't', b'h')\n",
    "E         Right contains one more item: (b' ', b'ver')\n"
   ],
   "id": "cdb8ff06d8cc6af7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "At index 92 diff: (b' c', b'om') != (b't', b'h')\n",
    "E         Right contains one more item: (b' ', b'ver')\n"
   ],
   "id": "cdd96fd4c2329b9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T18:25:12.077477Z",
     "start_time": "2025-08-08T18:25:04.098401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "def merge_word(word: tuple, best_pair: tuple, new_token_id: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Efficiently merges all occurrences of a pair in a word tuple.\n",
    "    This is the optimal single-pass approach.\n",
    "    \"\"\"\n",
    "    new_word = []\n",
    "    i = 0\n",
    "    # The loop condition ensures we only pass through the word once.\n",
    "    while i < len(word):\n",
    "        # This is a fast, constant-time check at each position.\n",
    "        # It peeks ahead by one without needing a new scan.\n",
    "        if i < len(word) - 1 and (word[i], word[i+1]) == best_pair:\n",
    "            # If we find the pair, we append the new token...\n",
    "            new_word.append(new_token_id)\n",
    "            # ...and crucially, we jump the index forward by 2.\n",
    "            i += 2\n",
    "        else:\n",
    "            # If there's no pair, we just copy the current token...\n",
    "            new_word.append(word[i])\n",
    "            # ...and move the index forward by only 1.\n",
    "            i += 1\n",
    "\n",
    "    return tuple(new_word)\n",
    "\n",
    "# --- Example ---\n",
    "# a = (0, 1, 2, 3, 4, 5, 3, 4, 7, 3, 4, 9, 3, 1, 4, 2, 5, 4, 3, 4, 3)\n",
    "best_pair = (3, 4)\n",
    "new_token_id = -99\n",
    "\n",
    "final_word = merge_word(a, best_pair, new_token_id)\n",
    "# print(final_word)\n",
    "# Correct Output: (0, 1, 2, -99, 5, -99, 7, -99, 9, 3, 1, 4, 2, 5, 4, -99, 3)"
   ],
   "id": "5ee580edfbb5e50e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980 μs ± 10.2 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "927afab711fc7be7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
